{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70149b0c",
   "metadata": {},
   "source": [
    "# Ejercicio 2 KNN\n",
    "\n",
    "Martin Alejandro Flores Saldaña - 22170647\n",
    "\n",
    "\n",
    "## How does KNN handle multi-class classification problems?\n",
    "\n",
    "K-Nearest Neighbors (KNN) stands as a fundamental algorithm, wielding versatility in handling both classification and regression tasks. In this article, we will understand what are KNNs and how they handle multi-classification problems.\n",
    "\n",
    "## What are k-nearest neighbors (KNNs)?\n",
    "\n",
    "K-Nearest Neighbors (KNN) can used for both classification and regression tasks. It belongs to the category of supervised learning, meaning it learns from labeled data to make predictions on new, unseen data. It comes under lazy learning algorithms as there is no training time involved instead it memorizes the entire dataset and makes predictions based on the similarity of new points and existing points in the dataset.\n",
    "\n",
    "## Distance Metrics in KNN\n",
    "\n",
    "We measure the similarity between data points using distance metrics. There are several distance metrics are used in KNN. The most frequently used are Euclidean distance, Manhattan distance, and Minkowski distance.\n",
    "\n",
    "  1.  Euclidean Distance: This is the straight-line distance between two points in n-dimensional space. Imagine points on a grid – Euclidean distance calculates the shortest path between them. It's widely used due to its geometric intuitiveness.\n",
    "  2.  Manhattan Distance: This metric represents the total distance traveled along each axis (horizontal and vertical movements) to get from one point to another. Imagine traveling only by blocks in a city grid – Manhattan distance captures this restricted movement.\n",
    "  3.  Minkowski Distance: This is a more general formula that encompasses both Euclidean and Manhattan distances as special cases. It introduces a parameter 'p' that allows for different ways of computing the distance. When 'p' equals 2, it becomes Euclidean distance. When 'p' equals 1, it transforms into Manhattan distance. Minkowski distance offers flexibility for exploring alternative distance measures.\n",
    "\n",
    "## KNN for Multi-Class classification\n",
    "\n",
    "KNN offers a versatile approach to multi-classification tasks, various steps for performing knn for multi-classification are:\n",
    "\n",
    "  1.  Data Preprocessing - Split the dataset into train and test after performing data scaling.\n",
    "  2.  Choosing the 'K' value - Choose the optimal value of 'K'.\n",
    "  3.  Training the model - Model stores the entire dataset into memory.\n",
    "  4.  Classifying test data points - For each data point, calculate the distance of it from its 'K' nearest neighbors and assign the test point to the class label with the highest number of neighbors.\n",
    "  5.  Evaluating Performance - Evaluate performance using different performance metrics like accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68b94c",
   "metadata": {},
   "source": [
    "Step 1: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f39980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ad8cf",
   "metadata": {},
   "source": [
    "Step 2: Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf71f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Unnamed: 0                        20000 non-null  int64  \n",
      " 1   NAME                              20000 non-null  object \n",
      " 2   USER_ID                           20000 non-null  int64  \n",
      " 3   HOURS_DATASCIENCE                 19986 non-null  float64\n",
      " 4   HOURS_BACKEND                     19947 non-null  float64\n",
      " 5   HOURS_FRONTEND                    19984 non-null  float64\n",
      " 6   NUM_COURSES_BEGINNER_DATASCIENCE  19974 non-null  float64\n",
      " 7   NUM_COURSES_BEGINNER_BACKEND      19982 non-null  float64\n",
      " 8   NUM_COURSES_BEGINNER_FRONTEND     19961 non-null  float64\n",
      " 9   NUM_COURSES_ADVANCED_DATASCIENCE  19998 non-null  float64\n",
      " 10  NUM_COURSES_ADVANCED_BACKEND      19992 non-null  float64\n",
      " 11  NUM_COURSES_ADVANCED_FRONTEND     19963 non-null  float64\n",
      " 12  AVG_SCORE_DATASCIENCE             19780 non-null  float64\n",
      " 13  AVG_SCORE_BACKEND                 19916 non-null  float64\n",
      " 14  AVG_SCORE_FRONTEND                19832 non-null  float64\n",
      " 15  PROFILE                           20000 non-null  object \n",
      "dtypes: float64(12), int64(2), object(2)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://github.com/umdalecs/IA-agodic2025/raw/main/datasets/dataset-tortuga.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c89bf",
   "metadata": {},
   "source": [
    "Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40285b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USER_ID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOURS_DATASCIENCE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOURS_BACKEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOURS_FRONTEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_COURSES_BEGINNER_DATASCIENCE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_COURSES_BEGINNER_BACKEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_COURSES_BEGINNER_FRONTEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_COURSES_ADVANCED_DATASCIENCE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_COURSES_ADVANCED_BACKEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_COURSES_ADVANCED_FRONTEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_SCORE_DATASCIENCE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_SCORE_BACKEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_SCORE_FRONTEND</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROFILE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "Unnamed: 0                          0\n",
       "NAME                                0\n",
       "USER_ID                             0\n",
       "HOURS_DATASCIENCE                   0\n",
       "HOURS_BACKEND                       0\n",
       "HOURS_FRONTEND                      0\n",
       "NUM_COURSES_BEGINNER_DATASCIENCE    0\n",
       "NUM_COURSES_BEGINNER_BACKEND        0\n",
       "NUM_COURSES_BEGINNER_FRONTEND       0\n",
       "NUM_COURSES_ADVANCED_DATASCIENCE    0\n",
       "NUM_COURSES_ADVANCED_BACKEND        0\n",
       "NUM_COURSES_ADVANCED_FRONTEND       0\n",
       "AVG_SCORE_DATASCIENCE               0\n",
       "AVG_SCORE_BACKEND                   0\n",
       "AVG_SCORE_FRONTEND                  0\n",
       "PROFILE                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.select_dtypes(include=np.number).columns.tolist()\n",
    "features = features[1:]\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[features] = pd.DataFrame(imputer.fit_transform(data[features]), columns=features)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3346f2d",
   "metadata": {},
   "source": [
    "Step 4: Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b61750",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['PROFILE', 'NAME', 'USER_ID'], axis = 1)\n",
    "y = data['PROFILE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e88524",
   "metadata": {},
   "source": [
    "Step 5: Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9684291",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1a29",
   "metadata": {},
   "source": [
    "Step 6: Finding the optimal value of 'K'\n",
    "\n",
    "We find the optimal value of 'K' simply by trying out multiple values of 'K' and checking which performs the best.\n",
    "\n",
    "'K' refers to the number of nearest neighbors to consider while making predictions. It is the most important hyperparameter in KNN. For example, if K = 3, the algorithm will look at the three closest data points to the point we are trying to classify and assign the majority class label among the neighbors to the new data point.\n",
    "\n",
    "The value of K depends on our data. We avoid even values of K since it will lead to conflict while making predictions. We usually find this value by trying out different values for 'K' and see which value is giving us better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}\n",
    "for k in range(3, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    acc[k] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# PLotting K v/s accuracy graph\n",
    "plt.plot(range(3,30,2), acc.values())\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
